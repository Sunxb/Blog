---
title: iOS 音视频技术 视频录制
date: 2018-07-06 16:19:13
tags: [iOS, 音视频]
---

#### 前言
伴随着大火的短视频应用，正好自己也有点时间，就稍微学习了一下视频相关的内容。

这种多媒体技术并没有想象的那么简单，这算是一个技术方向了。我把这些视频相关的技术分为了两部分，暂且叫做应用层面和底层技术层面（自己取得名字并不准确）。

应用层面可以理解为调用一些系统的api或者使用一些三方的框架，完成项目中的需求。从一个视频类app的流程来说，可能就要包括视频的录制，视频的处理（多段合成一段，添加背景音乐等），视频的播放等，当然了还包括一些滤镜效果，美颜效果，甚至是一些特效。

底层技术呢，就包括视频如何编码解码，相机滤镜美颜特效的一些实现。

坦白的说，从这两个方面来说，我都很菜，这段时间的学习就算是这方面一个进阶的过程吧。首先先从应用的角度来入手，毕竟有项目驱动的话，首先咱得先把某些效果给实现了，然后再考虑他们底层一些的技术。

#### 视频入门

>视频实质：
纯粹的视频（不包括音频）实质上就是一组帧图片，经过视频编码成为视频（video）文件再把音频（audio）文件有些还有字幕文件组装在一起成为我们看到的视频（movie）文件。1秒内出现的图片数就是帧率，图片间隔越小画面就越流畅，所以帧率越高效果就越好，需要的存储空间也就越多。

>视频格式：
MP4、MOV、AVI、RMVB这些播放格式其实都是封装格式，除了RMVB比较特殊外，其他格式内封装的视频编码格式都是H264，H264以高压缩率闻名于世，压缩效率比MEPG-2提升一倍多，但是世上没有两全其美的事，H264的解码难度提高了3倍多。

这两个概念就足以为我自己扫盲了。我们之前接触到的视频文件，其实我们不能单一把它当做一个文件，其实他是一种封装。它包括了纯粹的视频，也就是一连串的图片，包括音频，还可能包括了字幕。

<!-- more -->

#### 视频录制

我上网看了很多的文章，总结起来实现视频的录制有三种方法可以用。

1. UIImagePickerController
2. AVCaptureSession + AVCaptureMovieFileOutput
3. AVCaptureSession + AVAssetWriter

下面我们来分别说一下这三种方式的。

第一种：UIImagePickerController是使用起来最简单的，当然可定制化也是最低的，只能设置一些简单的参数来实现基本的视频录制的效果。如果你想自定义录制界面的UI，那你就只能抛弃这个简单的方法了。

第二、三两种方式要使用AVFoundation框架。
在AVFoundation框架中，关于视频录制的是要的类是AVCaptureSession，他负责调配输入和输出，算是总的管理。单独管理输入的是AVCaptureDeviceInput这个类。

AVFoundation中类很多，一个类会有各种属性，用起来比较麻烦。我们第一次使用就先着重了解这个整体流程和主要的那几个类。

第二种方法中使用了AVCaptureMovieFileOutput来作为输出，这是一个需要很少配置就可以直接输出视频的类，什么意思呢，也就是使用第二种AVCaptureSession + AVCaptureMovieFileOutput的方式录制视频，在你结束录制之后，AVCaptureMovieFileOutput会帮你直接生成一个视频文件到你指定的路径下，好处就是便捷，直接输出了视频文件。

第三种方法我个人觉得是最麻烦的，因为它处理的最原始的数据，而且视频数据和音频数据是分开处理，同时这也提高了这种方法的可定制性。

这种方法是通过AVCaptureVideoDataOutput和AVCaptureAudioDataOutput 分别拿到原始的视频和音频的数据，再进行处理。我们拿到这些原始的数据流可以来为设置很多参数，也可以添加背景音乐水印等。然后通过AVAssetWriter把这些数据流处理合成视频文件。

当然了，第二和三两种方法中，我们还需要**AVCaptureVideoPreviewLayer**来实时预览摄像头的画面。（也就是说我们摄像头捕获的画面，是通过这个类来管理展示的）

#### 代码示例和DEMO

这部分具体的操作逻辑就是上面描述的这个样子，主要的东西都在代码上。每个功能类的初始化，各种属性配置，使用AVAssetWriter时数据时如何写入的，这都是一个个麻烦的点。还好我从网上发现了一份特别棒的代码，然后照着大神的代码敲了一遍，然后针对我想实现的功能做了一点点修改，我把改后的代码放到百度网盘了。  

[这是我的DEMO，大家可以下载来看](https://pan.baidu.com/s/1zh-z2VARU33KzZ8ywC6R4Q)


下面是第二种方法里面的一段代码，从中可以看出整个流程来

```objc
#pragma mark - 主要过程
- (void)setUpWithType:(VideoViewType)type {
    /// -1. 提前异步创建存储路径 
    dispatch_async(dispatch_get_main_queue(), ^{
        [self videoFold];
    });
    
    ///0. 初始化捕捉会话，数据的采集都在会话中处理
    [self setUpInit];
    
    ///1. 设置视频的输入
    [self setUpVideo];
    
    ///2. 设置音频的输入
    [self setUpAudio];
    
    ///3.添加写入文件的fileoutput
    [self setUpFileOut];
    
    ///4. 视频的预览层
    [self setUpPreviewLayerWithType:type];
    
    ///5. 开始采集画面
    [self.session startRunning];
    
    
}
```

这个地方要声明一下，那个第-1步提前异步创建存储路径是我加上的，之前代码里面没有，为什么要加这一步呢？

再点击了开始录制按钮之后呢，会出现短暂的卡顿然后才开始录制，我分析了一下可能是在第3步的时候有创建路径的操作，大家都知道，都文件的操作是比较耗时的，所以我才在最开始就先异步把路径提前创建好了，然后正真开始录制的时候就会免去这一步耗时的操作，体验好一些，当然这是我的想法。

#### 视频录制的细节功能

我们从项目开始讲起吧 ~ 

![项目结构](https://upload-images.jianshu.io/upload_images/1491333-93a8da11d06be6bb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这是项目结构，我提前声明一下，那个RecordVideo文件中我是照着大神的FileOut文件中的代码敲得（也就是视频录制的第二种方法），里面有一些小改动。然后针对第三种方法的代码修改我都是直接在AVAssetWriter这个文件中直接改的。

**下面是重点**

原来这份代码只是从三个方面实现了视频录制的功能，三种方法实现的效果都是一样的，就是简单的视频录制。

但是在实际的项目中，我们有时候会遇到这么一个需求，那就是在录制的过程中暂停，然后恢复录制。

我从网上看了一下，找到了两种实现方法。一种是通过暂停时候的时间偏移量计算来实现，第二种是多段视频拼接。第一种我暂时还没能深入的了解，所以我通过修改AVAssetWriter这个文件中的代码，来实现一下**多段视频拼接**的思路。

我的修改是这样的：

1. 点击开始录制是开始录制第一段视频，点击停止的时候就停止录制并生成第一段视频 （之前是点击了停止生成视频直接跳到下一级页面播放了）
2. 再一次点击开始录制的时候，开始录制第二段，点击停止时停止录制并生成第二段。
3. 以此类推
4. 在view上我添加了一个录制完成的button，点击这个button就开始把之前的多段视频合成一段。（点击button之后注意看xcode的打印台）
5. 合成完成之后。直接跳转到下一个页面预览我们生成的视频文件。

![示例页面](https://upload-images.jianshu.io/upload_images/1491333-ff7671c7a4df3613.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

视频合成的代码可以去FMWVideoView这个类中的下面方法中看，我给了很多注释。

```objc
//////////////// 视频合成////////////
- (void)showFiles{}
```

上面方法的代码也有很多不足的地方，比如说如果给整个视频录制规定一个最大时间长度，上面实现的分段录制并没有收到这个最大时间的限制，这都是要进一步完善的地方，重点在于这个分段录制合成的思路。

#### 两点补充

1. 使用AVAssetWriter完成视频录制

    在用AVAssetWriter实现录制的时候，视频数据和音频数据分别是使用AVCaptureVideoDataOutput和AVCaptureAudioDataOutput来进行输出，他与之前的AVCaptureMovieFileOutput输出不同的是，AVCaptureMovieFileOutput会直接输出来视频文件，但是AVCaptureVideoDataOutput和AVCaptureAudioDataOutput输出的是原始的数据，再结合AVAssetWriter的把原始数据写成文件的能力来实现整个录制过程。

    AVAssetWriter实现录制视频相对来说麻烦一点，具体麻烦在把采集到的数据写成文件的这个过程。其实具体的实现流程并没有什么难懂，关键是这写类的用法问题。还有在写入文件时，视频和音频是分开处理的。具体的用法，代码写的很清楚，大家可以看一下。

2. 关于视频更改背景音乐的思考

    上面说到两个视频合成一个视频的例子，其实更改背景音乐用到的就是这种方法。
    
    举个例子说，就像我们说过的，我们要把A和B两个视频合成一个新的视频，我们会创建一个视频轨道一个音频轨道，然后把A和B的视频部分提取出来加到视频轨道中，音频部分提取出来加到音频轨道中，然后用这两个轨道合成一个文件。我们在更改背景音乐的时候，就是要处理这个音频轨道，在这个音频轨道中，我们不再是添加之前文件的音频部分，而且把我们需要的那个背景音乐添加到音频轨道中，用添加了背景音乐的音频轨道和视频轨道合成视频文件。
    
    当然了，这里面还涉及一些是否保留原音，或者或者跟范围有关的一些问题，大家可以自己再研究一下。

#### 接下来学习
滤镜效果。


#### 特别感谢

特别感谢大神的代码，不胜感激，附上大神的github主页。
https://github.com/suifengqjn


#### 参考文章
https://www.cnblogs.com/zy1987/p/4520118.html

http://gcblog.github.io/2017/03/22/iOS%E4%B8%89%E7%A7%8D%E5%BD%95%E5%88%B6%E8%A7%86%E9%A2%91%E6%96%B9%E5%BC%8F%E8%AF%A6%E7%BB%86%E5%AF%B9%E6%AF%94/

http://ios.jobbole.com/85069/

https://www.jianshu.com/p/174bb4f539cc


音视频相关的东西太多太多，我们一边学习，一边领悟吧。


